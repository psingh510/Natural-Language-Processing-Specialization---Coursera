{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6297d31-5637-46dd-8d99-9a8023c9827f",
   "metadata": {},
   "source": [
    "# Deep N-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b07ee7-36fc-4c0a-ba73-44069b22e201",
   "metadata": {},
   "source": [
    "1. How to convert a line of text into a tensor\n",
    "2. Create an iterator to feed data to the model\n",
    "3. Define a GRU model using trax\n",
    "4. Train the model using trax\n",
    "5. Compute the accuracy of your model using the perplexity\n",
    "6. Predict using your own model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b0029f7-f2f4-4a2a-8224-00879e74eae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import trax\n",
    "import trax.fastmath.numpy as np\n",
    "import pickle\n",
    "import numpy\n",
    "import random as rnd\n",
    "from trax import fastmath\n",
    "from trax import layers as tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ca80c15-eb87-4b0e-864f-5d37192bc1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "with open('./data/shakespeare.txt','r') as f:\n",
    "    files = f.read()\n",
    "    for line in files:\n",
    "        striped_line = line.strip()\n",
    "        if striped_line:\n",
    "            lines.append(striped_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "401ba78d-6417-418d-a32d-2859dc88df8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "230397"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "baf0d53e-5f5f-4f21-a1bb-f6542992964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert everything in lower case\n",
    "for i, line in enumerate(lines):\n",
    "    lines[i] = line.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "49eb8bb8-97d0-4e06-b1c8-e8bedf220e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines for training: 229397\n",
      "Number of lines for validation: 1000\n"
     ]
    }
   ],
   "source": [
    "eval_lines = lines[-1000:] # Create a holdout validation set\n",
    "lines = lines[:-1000] # Leave the rest for training\n",
    "\n",
    "print(f\"Number of lines for training: {len(lines)}\")\n",
    "print(f\"Number of lines for validation: {len(eval_lines)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d4529d-8f28-4943-8228-fb7cde59adad",
   "metadata": {},
   "source": [
    "### Convert a line to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64a32902-daf4-492c-95d9-1796284d510c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_to_tensor(line, EOS_int = 1):\n",
    "    res = []\n",
    "    for c in line:\n",
    "        res.append(ord(c))\n",
    "    res.append(EOS_int)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c561203-60bf-4fb3-ad3b-bb64a929035f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[73, 32, 97, 109, 32, 108, 101, 97, 114, 110, 105, 110, 103, 32, 78, 76, 80, 1]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_to_tensor('I am learning NLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "683f2073-d5d2-4605-9869-6d4e64e3f506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(batch_size, max_length,data_lines, line_to_tensor = line_to_tensor, shuffle=True):\n",
    "    index = 0\n",
    "    num_of_lines = len(data_lines)\n",
    "    line_index = [*range(num_of_lines)]\n",
    "    curr_batch = []\n",
    "    if shuffle:\n",
    "        rnd.shuffle(line_index)\n",
    "\n",
    "    while True:\n",
    "\n",
    "        if index >= num_of_lines:\n",
    "            index = 0 \n",
    "            if shuffle:\n",
    "                rnd.shuffle(line_index)\n",
    "\n",
    "        line = data_lines[line_index[index]]\n",
    "\n",
    "        if len(line) < max_length:\n",
    "            curr_batch.append(line)\n",
    "\n",
    "        index += 1\n",
    "\n",
    "        if len(curr_batch) == batch_size:\n",
    "            batch = []\n",
    "            mask = []\n",
    "            for l in curr_batch:\n",
    "                tensor = line_to_tensor(l)\n",
    "                pad = [0]*(max_length - len(tensor))\n",
    "                batch.append(tensor+pad)\n",
    "                mask.append(len(tensor)*[1] + len(pad)*[0])\n",
    "            batch_np_arr = np.array(batch)\n",
    "            mask_np_arr = np.array(mask)\n",
    "\n",
    "            yield batch_np_arr, batch_np_arr, mask_np_arr\n",
    "\n",
    "            cur_batch = []\n",
    "            \n",
    "\n",
    "                \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af813ed7-d910-4305-994d-98e2e66e544c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([[49, 50, 51, 52, 53, 54, 55, 56, 57,  1],\n",
       "        [50, 51, 52, 53, 54, 55, 56, 57, 48,  1]], dtype=int32),\n",
       " Array([[49, 50, 51, 52, 53, 54, 55, 56, 57,  1],\n",
       "        [50, 51, 52, 53, 54, 55, 56, 57, 48,  1]], dtype=int32),\n",
       " Array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try out your data generator\n",
    "tmp_lines = ['12345678901', #length 11\n",
    "             '123456789', # length 9\n",
    "             '234567890', # length 9\n",
    "             '345678901'] # length 9\n",
    "\n",
    "# Get a batch size of 2, max length 10\n",
    "tmp_data_gen = data_generator(batch_size=2, \n",
    "                              max_length=10, \n",
    "                              data_lines=tmp_lines,\n",
    "                              shuffle=False)\n",
    "\n",
    "# get one batch\n",
    "tmp_batch = next(tmp_data_gen)\n",
    "\n",
    "# view the batch\n",
    "tmp_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1118eb8e-ae29-431d-b3a0-087db80ec935",
   "metadata": {},
   "source": [
    "The way the iterator is currently defined, it will keep providing batches forever.\n",
    "Although it is not needed, we want to show you the itertools.cycle function which is really useful when the generator eventually stops\n",
    "Notice that it is expected to use this function within the training function further below\n",
    "Usually we want to cycle over the dataset multiple times during training (i.e. train for multiple epochs).\n",
    "For small datasets we can use itertools.cycle to achieve this easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c39e27bb-1df6-471b-998d-8423b2a21f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "infinite_data_generator = itertools.cycle(\n",
    "    data_generator(batch_size=2, max_length=10, data_lines=tmp_lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d644bde-2f90-44e1-bcd3-0748af9add18",
   "metadata": {},
   "source": [
    "### GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "babad2a9-051e-48c1-a6f2-1fbf992199f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GRULM(vocab_size=256, d_model=512, n_layers=2, mode='train'):\n",
    "    \"\"\"Returns a GRU language model.\n",
    "\n",
    "    Args:\n",
    "        vocab_size (int, optional): Size of the vocabulary. Defaults to 256.\n",
    "        d_model (int, optional): Depth of embedding (n_units in the GRU cell). Defaults to 512.\n",
    "        n_layers (int, optional): Number of GRU layers. Defaults to 2.\n",
    "        mode (str, optional): 'train', 'eval' or 'predict', predict mode is for fast inference. Defaults to \"train\".\n",
    "\n",
    "    Returns:\n",
    "        trax.layers.combinators.Serial: A GRU language model as a layer that maps from a tensor of tokens to activations over a vocab set.\n",
    "    \"\"\"\n",
    "    model = tl.Serial( \n",
    "      tl.ShiftRight(mode=mode), # Stack the ShiftRight layer\n",
    "      tl.Embedding(vocab_size=vocab_size,d_feature=d_model), # Stack the embedding layer\n",
    "      *(tl.GRU(n_units=d_model) for i in range(n_layers)), # Stack GRU layers of d_model units keeping n_layer parameter in mind (use list comprehension syntax)\n",
    "      tl.Dense(n_units=vocab_size), # Dense layer\n",
    "      tl.LogSoftmax(), # Log Softmax\n",
    "    ) \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7084cf3-27da-4c49-b1c2-425a46cb4fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serial[\n",
      "  Serial[\n",
      "    ShiftRight(1)\n",
      "  ]\n",
      "  Embedding_256_512\n",
      "  GRU_512\n",
      "  GRU_512\n",
      "  Dense_256\n",
      "  LogSoftmax\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "model = GRULM()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3814f038-8fdd-4157-9640-52fa714175c8",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "58ddb719-c48c-45ed-a699-98338c33483e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of used lines from the dataset: 230397\n",
      "Batch size (a power of 2): 32\n",
      "Number of steps to cover one epoch: 7199\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "max_length = 64\n",
    "def n_used_lines(lines, max_length):\n",
    "    '''\n",
    "    Args: \n",
    "    lines: all lines of text an array of lines\n",
    "    max_length - max_length of a line in order to be considered an int\n",
    "    output_dir - folder to save your file an int\n",
    "    Return:\n",
    "    number of efective examples\n",
    "    '''\n",
    "\n",
    "    n_lines = 0\n",
    "    for l in lines:\n",
    "        if len(l) <= max_length:\n",
    "            n_lines += 1\n",
    "    return n_lines\n",
    "\n",
    "num_used_lines = n_used_lines(lines, 32)\n",
    "print('Number of used lines from the dataset:', num_used_lines)\n",
    "print('Batch size (a power of 2):', int(batch_size))\n",
    "steps_per_epoch = int(num_used_lines/batch_size)\n",
    "print('Number of steps to cover one epoch:', steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c583aeb6-7fa8-4d1d-858c-c3e4d4d3dd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trax.supervised import training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e0799e97-e740-47d0-b417-59fdcb7960cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, data_generator, lines, eval_lines, batch_size=32, max_length=64, n_steps=1, output_dir='model/'): \n",
    "    bare_train_generator = data_generator(batch_size,max_length,lines)\n",
    "    infinite_train_generator = itertools.cycle(bare_train_generator)\n",
    "    \n",
    "    bare_eval_generator = data_generator(batch_size,max_length,eval_lines)\n",
    "    infinite_eval_generator = itertools.cycle(bare_eval_generator)\n",
    "\n",
    "    train_task = training.TrainTask(\n",
    "        labeled_data = infinite_train_generator,\n",
    "        loss_layer = tl.CrossEntropyLoss(),\n",
    "        optimizer = trax.optimizers.Adam(learning_rate = 0.0005)\n",
    "    )\n",
    "    eval_task = training.EvalTask(\n",
    "        labeled_data = infinite_eval_generator,\n",
    "        metrics = [tl.CrossEntropyLoss(),tl.Accuracy()],\n",
    "        n_eval_batches = 3\n",
    "    )\n",
    "    training_loop = training.Loop(\n",
    "        model,\n",
    "        train_task,\n",
    "        eval_tasks = [eval_task],\n",
    "        output_dir = output_dir\n",
    "    )\n",
    "    return training_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "83f1d697-e822-4250-948a-ec1572cd9f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pallavisingh/anaconda3/envs/mlprojects/lib/python3.11/site-packages/jax/_src/xla_bridge.py:1183: UserWarning: jax.host_count has been renamed to jax.process_count. This alias will eventually be removed; please update your code.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Train the model 1 step and keep the `trax.supervised.training.Loop` object.\n",
    "output_dir = './model/'\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(output_dir)\n",
    "except OSError as e:\n",
    "    pass\n",
    "\n",
    "training_loop = train_model(GRULM(), data_generator, lines=lines, eval_lines=eval_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a3edf8-edc4-487e-9c3b-f59a894b1deb",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d61259a1-f1cf-4ddb-a8d8-63e4815269df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(preds, target):\n",
    "\n",
    "    log_p = np.sum(preds* tl.one_hot(target, pred.shape[-1]), axis = -1)\n",
    "    non_pad = 1.0 - np.equal(target,0)\n",
    "    log_p = log_p * non_pad \n",
    "    log_ppx = np.sum(log_p, axis = 1) / np.sum(non_pad, axis = 1)\n",
    "    log_ppx = np.mean(log_ppx)\n",
    "\n",
    "    return -log_ppx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c81c63-88c4-479f-b767-d107fa27a697",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
