{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "156b653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import numpy as np\n",
    "import string \n",
    "# Punctuation characters\n",
    "punct = set(string.punctuation)\n",
    "\n",
    "# Morphology rules used to assign unknown word tokens\n",
    "noun_suffix = [\"action\", \"age\", \"ance\", \"cy\", \"dom\", \"ee\", \"ence\", \"er\", \"hood\", \"ion\", \"ism\", \"ist\", \"ity\", \"ling\", \"ment\", \"ness\", \"or\", \"ry\", \"scape\", \"ship\", \"ty\"]\n",
    "verb_suffix = [\"ate\", \"ify\", \"ise\", \"ize\"]\n",
    "adj_suffix = [\"able\", \"ese\", \"ful\", \"i\", \"ian\", \"ible\", \"ic\", \"ish\", \"ive\", \"less\", \"ly\", \"ous\"]\n",
    "adv_suffix = [\"ward\", \"wards\", \"wise\"]\n",
    "\n",
    "# Additive smoothing parameter\n",
    "alpha = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f606adab",
   "metadata": {},
   "source": [
    "### Important functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "027def1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_states(target_corpus):\n",
    "    \n",
    "    states = set()\n",
    "    observations = set()\n",
    "    \n",
    "    for senten in target_corpus:\n",
    "        for tup in senten:\n",
    "            \n",
    "            word , label = tup\n",
    "            \n",
    "            states.add(label)\n",
    "            \n",
    "            observations.add(word)\n",
    "            \n",
    "    observations.add('<s>')\n",
    "    states.add('<s>')\n",
    "    \n",
    "    return tuple(states), tuple(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d963f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_unk(tok):\n",
    "    \"\"\"\n",
    "    Assign unknown word tokens\n",
    "    \"\"\"\n",
    "    # Digits\n",
    "    if any(char.isdigit() for char in tok):\n",
    "        return \"--unk_digit--\"\n",
    "\n",
    "    # Punctuation\n",
    "    elif any(char in punct for char in tok):\n",
    "        return \"--unk_punct--\"\n",
    "\n",
    "    # Upper-case\n",
    "    elif any(char.isupper() for char in tok):\n",
    "        return \"--unk_upper--\"\n",
    "\n",
    "    # Nouns\n",
    "    elif any(tok.endswith(suffix) for suffix in noun_suffix):\n",
    "        return \"--unk_noun--\"\n",
    "\n",
    "    # Verbs\n",
    "    elif any(tok.endswith(suffix) for suffix in verb_suffix):\n",
    "        return \"--unk_verb--\"\n",
    "\n",
    "    # Adjectives\n",
    "    elif any(tok.endswith(suffix) for suffix in adj_suffix):\n",
    "        return \"--unk_adj--\"\n",
    "\n",
    "    # Adverbs\n",
    "    elif any(tok.endswith(suffix) for suffix in adv_suffix):\n",
    "        return \"--unk_adv--\"\n",
    "\n",
    "    return \"--unk--\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c020ffa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_tag(line,vocab):\n",
    "    \n",
    "    if not line.split():\n",
    "        \n",
    "        word = \"--n--\"\n",
    "        tag = \"--s--\"\n",
    "        \n",
    "        return word, tag\n",
    "    else:\n",
    "        word,tag = line.split()\n",
    "        if word not in vocab:\n",
    "            word = assign_unk(word) \n",
    "        return word, tag\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05f2160a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(vocab, data_fp):\n",
    "    \"\"\"\n",
    "    Preprocess data\n",
    "    \"\"\"\n",
    "    orig = []\n",
    "    prep = []\n",
    "    punct = string.punctuation \n",
    "\n",
    "    # Read data\n",
    "    with open(data_fp, \"r\") as data_file:\n",
    "\n",
    "        for cnt, word in enumerate(data_file):\n",
    "\n",
    "            # End of sentence\n",
    "            if not word.split():\n",
    "                orig.append(word.strip())\n",
    "                word = \"--n--\"\n",
    "                prep.append(word)\n",
    "                continue\n",
    "\n",
    "            # Handle unknown words\n",
    "            elif word.strip() not in vocab:\n",
    "                orig.append(word.strip())\n",
    "                word = assign_unk(word)\n",
    "                prep.append(word)\n",
    "                continue\n",
    "\n",
    "            else:\n",
    "                orig.append(word.strip())\n",
    "                prep.append(word.strip())\n",
    "\n",
    "    assert(len(orig) == len(open(data_fp, \"r\").readlines()))\n",
    "    assert(len(prep) == len(open(data_fp, \"r\").readlines()))\n",
    "\n",
    "    return orig, prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d30dd72",
   "metadata": {},
   "source": [
    "### Importing Training Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2b9d83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"./data/WSJ_02-21.pos\", 'r') as f:\n",
    "    \n",
    "    training_corpus = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1079e797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In\\tIN\\n', 'an\\tDT\\n', 'Oct.\\tNNP\\n', '19\\tCD\\n', 'review\\tNN\\n']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_corpus[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282ca46d",
   "metadata": {},
   "source": [
    "### Importing Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "761aafcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"./data/hmm_vocab.txt\", 'r') as f:\n",
    "    \n",
    "    vocab_l = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1b56fee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zones', 'zoning', '{', '}', '']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_l[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4c83f485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary dictionary, key is the word, value is a unique integer\n",
      ":0\n",
      "!:1\n",
      "#:2\n",
      "$:3\n",
      "%:4\n",
      "&:5\n",
      "':6\n",
      "'':7\n",
      "'40s:8\n",
      "'60s:9\n",
      "'70s:10\n",
      "'80s:11\n",
      "'86:12\n",
      "'90s:13\n",
      "'N:14\n",
      "'S:15\n",
      "'d:16\n",
      "'em:17\n",
      "'ll:18\n",
      "'m:19\n",
      "'n':20\n"
     ]
    }
   ],
   "source": [
    "# vocab: dictionary that has the index of the corresponding words\n",
    "vocab = {}\n",
    "\n",
    "# Get the index of the corresponding words. \n",
    "for i, word in enumerate(sorted(vocab_l)): \n",
    "    vocab[word] = i       \n",
    "    \n",
    "print(\"Vocabulary dictionary, key is the word, value is a unique integer\")\n",
    "cnt = 0\n",
    "for k,v in vocab.items():\n",
    "    print(f\"{k}:{v}\")\n",
    "    cnt += 1\n",
    "    if cnt > 20:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6149d8",
   "metadata": {},
   "source": [
    "### Importing Testing Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7a53f3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the test corpus\n",
    "with open(\"./data/WSJ_24.pos\", 'r') as f:\n",
    "    y = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e3295f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A sample of the test corpus\n",
      "['The\\tDT\\n', 'economy\\tNN\\n', \"'s\\tPOS\\n\", 'temperature\\tNN\\n', 'will\\tMD\\n', 'be\\tVB\\n', 'taken\\tVBN\\n', 'from\\tIN\\n', 'several\\tJJ\\n', 'vantage\\tNN\\n']\n"
     ]
    }
   ],
   "source": [
    "print(\"A sample of the test corpus\")\n",
    "print(y[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb08dc24",
   "metadata": {},
   "source": [
    "### Corpus without tags (preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a80fc576",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,prep = preprocess(vocab,\"./data/test.words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "101b2382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the preprocessed test corpus:  34199\n",
      "This is a sample of the test_corpus: \n",
      "['The', 'economy', \"'s\", 'temperature', 'will', 'be', 'taken', 'from', 'several', '--unk--']\n"
     ]
    }
   ],
   "source": [
    "print('The length of the preprocessed test corpus: ', len(prep))\n",
    "print('This is a sample of the test_corpus: ')\n",
    "print(prep[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad64b121",
   "metadata": {},
   "source": [
    "### Instructions: Write a program that takes in the training_corpus and returns the three dictionaries mentioned above transition_counts, emission_counts, and tag_counts.\n",
    "\n",
    "1. emission_counts: maps (tag, word) to the number of times it happened.\n",
    "2. transition_counts: maps (prev_tag, tag) to the number of times it has appeared.\n",
    "3. tag_counts: maps (tag) to the number of times it has occured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0736c653",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dictionaries(training_corpus, vocab):\n",
    "    \n",
    "    transition_counts = defaultdict(int)\n",
    "    emission_counts = defaultdict(int)\n",
    "    tag_counts = defaultdict(int)\n",
    "    \n",
    "    prev_tag = '--s--'\n",
    "    \n",
    "    for word_tag in training_corpus:\n",
    "        \n",
    "        word, tag = get_word_tag(word_tag,vocab)\n",
    "        \n",
    "        transition_counts[(prev_tag,tag)] +=1\n",
    "        emission_counts[(tag, word)] +=1\n",
    "        tag_counts[tag] +=1\n",
    "        \n",
    "        prev_tag = tag\n",
    "        \n",
    "        \n",
    "        \n",
    "    return transition_counts,emission_counts,tag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "864539df",
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_counts,emission_counts,tag_counts = create_dictionaries(training_corpus, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0cabbe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = sorted(tag_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "74188023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#',\n",
       " '$',\n",
       " \"''\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " '--s--',\n",
       " '.',\n",
       " ':',\n",
       " 'CC',\n",
       " 'CD',\n",
       " 'DT',\n",
       " 'EX',\n",
       " 'FW',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'JJR',\n",
       " 'JJS',\n",
       " 'LS',\n",
       " 'MD',\n",
       " 'NN',\n",
       " 'NNP',\n",
       " 'NNPS',\n",
       " 'NNS',\n",
       " 'PDT',\n",
       " 'POS',\n",
       " 'PRP',\n",
       " 'PRP$',\n",
       " 'RB',\n",
       " 'RBR',\n",
       " 'RBS',\n",
       " 'RP',\n",
       " 'SYM',\n",
       " 'TO',\n",
       " 'UH',\n",
       " 'VB',\n",
       " 'VBD',\n",
       " 'VBG',\n",
       " 'VBN',\n",
       " 'VBP',\n",
       " 'VBZ',\n",
       " 'WDT',\n",
       " 'WP',\n",
       " 'WP$',\n",
       " 'WRB',\n",
       " '``']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99f1924",
   "metadata": {},
   "source": [
    "### Instructions: Implement predict_pos that computes the accuracy of your model.\n",
    "\n",
    "1. This is a warm up exercise.\n",
    "2. To assign a part of speech to a word, assign the most frequent POS for that word in the training set.\n",
    "3. Then evaluate how well this approach works. Each time you predict based on the most frequent POS for the given word, check whether the actual POS of that word is the same. If so, the prediction was correct!\n",
    "4. Calculate the accuracy as the number of correct predictions divided by the total number of words for which you predicted the POS tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "80db1b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_pos(prep, y, emission_counts, vocab, states):\n",
    "    num_correct = 0\n",
    "    for word, tup in zip(prep,y):\n",
    "        \n",
    "        tup_list = tup.split()\n",
    "        \n",
    "        if len(tup_list) ==2:\n",
    "            true_label = tup_list[1]\n",
    "            \n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "        count_final = 0\n",
    "        pos_final = ''  \n",
    "        if word in vocab:\n",
    "            \n",
    "            for pos in states:\n",
    "                \n",
    "                key = (pos,word)\n",
    "                \n",
    "                if key in emission_counts:\n",
    "                    \n",
    "                    count = emission_counts[key]\n",
    "                    \n",
    "                    if count_final < count:\n",
    "                        count_final = count\n",
    "                        pos_final = pos\n",
    "                         \n",
    "            if true_label == pos_final:\n",
    "                num_correct += 1\n",
    "                \n",
    "    return num_correct/len(y) , num_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "61db4f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8888563993099213, 30398)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_pos(prep, y, emission_counts, vocab, states)\n",
    "#print(f\"Accuracy of prediction using predict_pos is {accuracy_predict_pos:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c12d15b",
   "metadata": {},
   "source": [
    "# Hidden Markov Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fa2ea8",
   "metadata": {},
   "source": [
    "### Instructions: Implement the create_transition_matrix below for all tags. Your task is to output a matrix that computes equation 3 for each cell in matrix A.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6e760ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transition_matrix(alpha, tag_counts, transition_counts):\n",
    "    all_tags = sorted(tag_counts.keys())\n",
    "    num_tags = len(all_tags)\n",
    "    \n",
    "    A = np.zeros((num_tags,num_tags))\n",
    "    \n",
    "    trans_keys = set(transition_counts.keys())\n",
    "    \n",
    "    for i in range(num_tags):\n",
    "        \n",
    "        for j in range(num_tags):\n",
    "            \n",
    "            count = 0\n",
    "            \n",
    "            key = (all_tags[i],all_tags[j])\n",
    "            \n",
    "            if key in trans_keys:\n",
    "                \n",
    "                count = transition_counts[key]\n",
    "                \n",
    "            count_prev_tag = tag_counts[all_tags[i]]\n",
    "            \n",
    "            A[i,j] = (count + alpha) / (count_prev_tag + alpha * num_tags)\n",
    "            \n",
    "    return A     \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e409703e",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.001\n",
    "A = create_transition_matrix(alpha, tag_counts, transition_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d0361170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              RBS            RP           SYM        TO            UH\n",
      "RBS  2.217069e-06  2.217069e-06  2.217069e-06  0.008870  2.217069e-06\n",
      "RP   3.756509e-07  7.516775e-04  3.756509e-07  0.051089  3.756509e-07\n",
      "SYM  1.722772e-05  1.722772e-05  1.722772e-05  0.000017  1.722772e-05\n",
      "TO   4.477336e-05  4.472863e-08  4.472863e-08  0.000090  4.477336e-05\n",
      "UH   1.030439e-05  1.030439e-05  1.030439e-05  0.061837  3.092348e-02\n"
     ]
    }
   ],
   "source": [
    "A_sub = pd.DataFrame(A[30:35,30:35], index=states[30:35], columns = states[30:35] )\n",
    "print(A_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb916a7",
   "metadata": {},
   "source": [
    "### Instructions: Implement the create_emission_matrix below that computes the B emission probabilities matrix. \n",
    "\n",
    "Your function takes in alpha, the smoothing parameter, tag_counts, which is a dictionary mapping each tag to its respective count, the emission_counts dictionary where the keys are (tag, word) and the values are the counts. Your task is to output a matrix that computes equation 4 for each cell in matrix B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6a74366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emission_matrix (alpha, tag_counts, emission_counts,vocab):\n",
    "    \n",
    "    all_tags = sorted(tag_counts.keys())\n",
    "    num_tags = len(all_tags)\n",
    "    \n",
    "    \n",
    "    emiss_keys = set(list(emission_counts.keys()))\n",
    "    \n",
    "    no_words = len(vocab)\n",
    "    \n",
    "    B = np.zeros((num_tags,no_words))\n",
    "    \n",
    "    for i in range(num_tags):\n",
    "        \n",
    "        for j in range(no_words):\n",
    "            \n",
    "            count = 0\n",
    "            \n",
    "            key = (all_tags[i],vocab[j])\n",
    "            \n",
    "            if key in emiss_keys:\n",
    "                \n",
    "                count = emission_counts[key]\n",
    "                \n",
    "            count_tag = tag_counts[all_tags[i]]\n",
    "            \n",
    "            B[i,j] = (count + alpha) / (count_tag + alpha * no_words)\n",
    "            \n",
    "    return B  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3489101d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View Matrix position at row 0, column 0: 0.000006032\n",
      "View Matrix position at row 3, column 1: 0.000000720\n"
     ]
    }
   ],
   "source": [
    "# creating your emission probability matrix. this takes a few minutes to run. \n",
    "alpha = 0.001\n",
    "B = create_emission_matrix(alpha, tag_counts, emission_counts, list(vocab))\n",
    "\n",
    "print(f\"View Matrix position at row 0, column 0: {B[0,0]:.9f}\")\n",
    "print(f\"View Matrix position at row 3, column 1: {B[3,1]:.9f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "079f430a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              725      adroitly     engineers      promoted       synergy\n",
      "CD   8.201296e-05  2.732854e-08  2.732854e-08  2.732854e-08  2.732854e-08\n",
      "NN   7.521128e-09  7.521128e-09  7.521128e-09  7.521128e-09  2.257091e-05\n",
      "NNS  1.670013e-08  1.670013e-08  4.676203e-04  1.670013e-08  1.670013e-08\n",
      "VB   3.779036e-08  3.779036e-08  3.779036e-08  3.779036e-08  3.779036e-08\n",
      "RB   3.226454e-08  6.456135e-05  3.226454e-08  3.226454e-08  3.226454e-08\n",
      "RP   3.723317e-07  3.723317e-07  3.723317e-07  3.723317e-07  3.723317e-07\n"
     ]
    }
   ],
   "source": [
    "# Try viewing emissions for a few words in a sample dataframe\n",
    "cidx  = ['725','adroitly','engineers', 'promoted', 'synergy']\n",
    "\n",
    "# Get the integer ID for each word\n",
    "cols = [vocab[a] for a in cidx]\n",
    "\n",
    "# Choose POS tags to show in a sample dataframe\n",
    "rvals =['CD','NN','NNS', 'VB','RB','RP']\n",
    "\n",
    "# For each POS tag, get the row number from the 'states' list\n",
    "rows = [states.index(a) for a in rvals]\n",
    "# Get the emissions for the sample of words, and the sample of POS tags\n",
    "B_sub = pd.DataFrame(B[np.ix_(rows,cols)], index=rvals, columns = cidx )\n",
    "print(B_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8e7f46",
   "metadata": {},
   "source": [
    "# Viterbi Algorithm and Dynamic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f2c8dc",
   "metadata": {},
   "source": [
    "1. Initialization - In this part you initialize the best_paths and best_probabilities matrices that you will be populating in feed_forward.\n",
    "2. Feed forward - At each step, you calculate the probability of each path happening and the best paths up to that point.\n",
    "3. Feed backward: This allows you to find the best path with the highest probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "46bf84f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(states, tag_counts, A, B, corpus, vocab):\n",
    "    \n",
    "    # Get the total number of unique POS tags\n",
    "    num_tags = len(tag_counts)\n",
    "    best_probs = np.zeros((num_tags, len(corpus)))\n",
    "    best_paths = np.zeros((num_tags, len(corpus)), dtype = int)\n",
    "    \n",
    "    s_indx = states.index('--s--')\n",
    "    \n",
    "    for i in range(num_tags):\n",
    "        \n",
    "        if A[s_indx,i] == 0:\n",
    "            best_probs[i,0] = float('-inf')\n",
    "            \n",
    "        else:\n",
    "            best_probs[i,0] = math.log(A[s_indx,i]) + math.log(B[i,vocab[corpus[0]]])\n",
    "            \n",
    "            \n",
    "    return best_probs, best_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "57464581",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_probs, best_paths = initialize(states, tag_counts, A, B, prep, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8a718140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_probs[0,0]: -22.6098\n",
      "best_paths[2,3]: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Test the function\n",
    "print(f\"best_probs[0,0]: {best_probs[0,0]:.4f}\")\n",
    "print(f\"best_paths[2,3]: {best_paths[2,3]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbc8aab",
   "metadata": {},
   "source": [
    "### Instructions: Implement the viterbi_forward algorithm and store the best_path and best_prob for every possible tag for each word in the matrices best_probs and best_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "816573db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_forward(A,B,test_corpus, best_probs, best_paths, vocab):\n",
    "    \n",
    "    num_tags = best_probs.shape[0]\n",
    "    \n",
    "    for i in range(1, len(test_corpus)):\n",
    "        # For each unique POS tag that the current word can be\n",
    "        for j in range(num_tags):\n",
    "            \n",
    "            best_prob_i = float(\"-inf\")\n",
    "            best_path_i = None\n",
    "            \n",
    "            # For each POS tag that the previous word can be\n",
    "            for k in range(num_tags):\n",
    "                \n",
    "                if test_corpus[i] in vocab:\n",
    "                    prob = best_probs[k,i-1] +math.log(A[k,j]) + math.log(B[j,vocab[test_corpus[i]]])\n",
    "                    \n",
    "                else:\n",
    "                    prob = float(\"-inf\")\n",
    "                    \n",
    "                # check if this path's probability is greater than the best probability up to and before this point\n",
    "                if prob > best_prob_i:\n",
    "                    # Keep track of the best probability\n",
    "                    best_prob_i = prob\n",
    "                    # keep track of the POS tag of the previous word that is part of the best path\n",
    "                    best_path_i = k\n",
    "            # Save the best probability for the given current word's POS tag and the position of the current word inside the corpus\n",
    "            best_probs[j, i] = best_prob_i\n",
    "            \n",
    "            # Save the unique integer ID of the previous POS tag into best_paths matrix, for the POS tag of the current word\n",
    "            # and the position of the current word inside the corpus.\n",
    "            best_paths[j, i] = best_path_i\n",
    "\n",
    "    return best_probs, best_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "26f3f3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will take a few minutes to run => processes ~ 30,000 words\n",
    "best_probs, best_paths = viterbi_forward(A, B, prep, best_probs, best_paths, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ed7aa32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_probs[0,1]: -24.7822\n",
      "best_probs[0,4]: -49.5601\n"
     ]
    }
   ],
   "source": [
    "# Test this function \n",
    "print(f\"best_probs[0,1]: {best_probs[0,1]:.4f}\") \n",
    "print(f\"best_probs[0,4]: {best_probs[0,4]:.4f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3b9823",
   "metadata": {},
   "source": [
    "### Implement the viterbi_backward algorithm, which returns a list of predicted POS tags for each word in the corpus.\n",
    "\n",
    "Note that the numbering of the index positions starts at 0 and not 1.\n",
    "m is the number of words in the corpus.\n",
    "So the indexing into the corpus goes from 0 to m - 1.\n",
    "Also, the columns in best_probs and best_paths are indexed from 0 to m - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "508eb6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_backward(best_probs, best_paths, corpus, states):\n",
    "    \n",
    "    m = best_paths.shape[1]\n",
    "    \n",
    "    # Initialize array z, same length as the corpus\n",
    "    z = [None] * m\n",
    "    \n",
    "    # Get the number of unique POS tags\n",
    "    num_tags = best_probs.shape[0]\n",
    "    \n",
    "    # Initialize the best probability for the last word\n",
    "    best_prob_for_last_word = float('-inf')\n",
    "    \n",
    "    # Initialize pred array, same length as corpus\n",
    "    pred = [None] * m\n",
    "    \n",
    "    \n",
    "    # Go through each POS tag for the last word (last column of best_probs)\n",
    "    # in order to find the row (POS tag integer ID) \n",
    "    # with highest probability for the last word\n",
    "    for k in range(num_tags):\n",
    "        # If the probability of POS tag at row k \n",
    "        # is better than the previously best probability for the last word:\n",
    "        if best_probs[k, m-1] > best_prob_for_last_word:\n",
    "            # Store the new best probability for the last word\n",
    "            best_prob_for_last_word = best_probs[k, m-1]\n",
    "            # Store the unique integer ID of the POS tag\n",
    "            # which is also the row number in best_probs\n",
    "            z[m - 1] = k\n",
    "            \n",
    "    # Convert the last word's predicted POS tag\n",
    "    # from its unique integer ID into the string representation\n",
    "    # using the 'states' list\n",
    "    # store this in the 'pred' array for the last word\n",
    "    pred[m - 1] = states[z[m - 1]]\n",
    "    \n",
    "    ## Step 2 ##\n",
    "    # Find the best POS tags by walking backward through the best_paths\n",
    "    # From the last word in the corpus to the 0th word in the corpus\n",
    "    for i in range(m-1, 0, -1):\n",
    "        # Retrieve the unique integer ID of the POS tag for the word at position 'i' in the corpus\n",
    "        pos_tag_for_word_i = z[i]\n",
    "        \n",
    "        # In best_paths, go to the row representing the POS tag of word i\n",
    "        # and the column representing the word's position in the corpus\n",
    "        # to retrieve the predicted POS for the word at position i-1 in the corpus\n",
    "        z[i - 1] = best_paths[pos_tag_for_word_i, i]\n",
    "        \n",
    "        # Get the previous word's POS tag in string form\n",
    "        # Use the 'states' list, \n",
    "        # where the key is the unique integer ID of the POS tag,\n",
    "        # and the value is the string representation of that POS tag\n",
    "        pred[i - 1] = states[z[i - 1]]\n",
    "        \n",
    "\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e4430eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction for pred[-7:m-1] is: \n",
      " ['see', 'them', 'here', 'with', 'us', '.'] \n",
      " ['VB', 'PRP', 'RB', 'IN', 'PRP', '.'] \n",
      "\n",
      "The prediction for pred[0:8] is: \n",
      " ['DT', 'NN', 'POS', 'NN', 'MD', 'VB', 'VBN'] \n",
      " ['The', 'economy', \"'s\", 'temperature', 'will', 'be', 'taken']\n"
     ]
    }
   ],
   "source": [
    "# Run and test your function\n",
    "pred = viterbi_backward(best_probs, best_paths, prep, states)\n",
    "m=len(pred)\n",
    "print('The prediction for pred[-7:m-1] is: \\n', prep[-7:m-1], \"\\n\", pred[-7:m-1], \"\\n\")\n",
    "print('The prediction for pred[0:8] is: \\n', pred[0:7], \"\\n\", prep[0:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c69e28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
